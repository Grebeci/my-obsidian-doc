#### 标签项目简要描述



我的最近的项目是用户画像相关的，也就是标签系统。在刚接这个项目的时候，人还比较少，主要是我和领导在负责这个项目。最初，这个项目是服务于电召系统，后来被用于圈课运营，实现精准营销。

刚开始，也就是项目的一二期，为了快速丰富标签种类，我们算用Scala语言，spark作为数据处理引擎，用模板方法设计模式快速设计了一个跑标签的框架。

具体的抽象就是一个标签映射成一个 DataFrame , df 实际是一个sql逻辑，结构是 id -> tag1, tag2，然后跑这些df，把每个df通过id join起来，落盘为中间表。

因为一期二期主要侧重于标签的加工，所以我们构建了一个标签数仓。这个标签数仓不是按照标准的建模来的，因为主要是数据处理相关的项目，所以我们知识构建了两层，分别是DWD明细层和标签主题层。标签主题层就是标签跑批的结果。



我们面向Spark主要做了两个优化，第一是针对hive表字段不能删除的特点，但是我们标签经常会有上线线的需求，这样就带来一个问题，标签逻辑简单注释掉后，还需要对应字段置空。因此我们先落盘为JSON中间表，然后再起 hive任务把 JSON 表打平，由于later view 特点，不产出的字段会自动置空。



第二个优化是，对标签join的优化。多个 DataFrame 模仿map-reduce的思想， 把多个df先映射成json，然后对id进行group by ,最后reduce, reduce逻辑是每个标签json捏在一起。我们这样做可以并发五个一批，实现并发的join效果。时间加快3倍以上，内存减少50% 。



二期主要是重构的需求，主要诉求是加快标签的产出速度，在以往，我们标签加工的逻辑写在代码中，这就设计上线流程测试流程。而且由于人力的紧张，我们需要支持标签的开发，现在他们要求标签加工由他们的数据分析人员来做，我们主要关注于实现数据的跑批流程。因此，我们重构了标签系统，效果就是提供一个webui 的前端编辑，类似于Hue效果，标签加工人员只需要在 WebUI 提交sql，web后端把逻辑保存在数据库里。我们拉取标签加工逻辑进行跑批。基本实现标签加工和标签跑批的解耦的效果。后续我们加入了数据源检测，也就是标签数据源跑完后我们。

