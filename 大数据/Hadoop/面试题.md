### 一、架构相关

#### **1. YARN的结构是什么？**

**相关问题：**

- YARN集群的架构和工作原理 ？
- YARN集群的结构 ？

**AI-Prompt:** 

- YARN集群的架构是什么？

- YARN集群主要包含哪些组件
- Yarn集群运行时候的进程？

###### 理解

进程就两个，RM，NM。但是运行任务的时候会有 ApplicationMaster（AM）, Container进程。

组件 ：组件就是模块的意思。通常认为有 5 个 ，  ResourceManager、NodeManager、ApplicationMaster、Container和Scheduler

###### 答案

> （1）**ResourceManager**： RM是一个全局的资源管理器，负责整个系统的资源管理和分配，它主要由两个部分组成：调度器（Scheduler）和应用程序管理器（Application Manager）。
>
> （2）**ApplicationMaster（AM）** ：负责单个应用程序的资源管理和任务调度。它会向ResourceManager申请资源，并与NodeManager协商启动Container来运行任务。
>
> （3）**NodeManager** ： NodeManager是每个节点上的资源和任务管理器，一方面，它会定期地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，他接收并处理来自AM的Container启动和停止请求。
>
> （4）**Container**： Container是YARN中的资源抽象，封装了各种资源。一个应用程序会分配一个Container，这个应用程序只能使用这个Container中描述的资源。
>
> （5）**Scheduler**：负责根据预定策略分配集群资源。它会根据各个应用程序的需求和优先级，以及集群的整体资源状况，决定如何分配资源。



###### 通俗理解

```
ResourceManager : 管理所有 NodeManager 节点的资源，包括cpu，内存。
NodeManager ： 单个节点的资源和任务管理器。
Container ： 资源抽象。
ApplicationMaster ：运行单个任务时生成，负责这个任务的资源管理和任务调度。
```



#### **2. Yarn 提交任务的流程**

###### **相关问题：**

- Yarn 提交任务的步骤

###### 答案

> 1. 客户端向ResourceManager提交应用程序，包括应用程序的代码、配置和资源需求等信息。
> 2. ResourceManager为应用程序分配一个ApplicationMaster，并在集群中选择一个节点启动它。
> 3. ApplicationMaster向ResourceManager申请资源，并与NodeManager协商启动Container来运行任务。
> 4. 任务在Container中运行，ApplicationMaster负责监控任务的运行状态，并根据需要动态申请或释放资源。
> 5. 当应用程序运行完成后，ApplicationMaster向ResourceManager汇报运行结果，并释放所有占用的资源。



#### **3. YARN的资源调度三种模型了解吗**

###### 答案

> 1. **FIFO Scheduler**：顾名思义，FIFO Scheduler采用先进先出的策略进行调度。所有的任务都放在一个队列中，只有执行完一个任务后，才会进行下一个任务。
> 2. **Capacity Scheduler**：Capacity Scheduler是由Yahoo!开发的多用户调度器。它以队列为单位划分资源，每个队列可以设定一定比例的资源最低保证和使用上限。每个用户也可以设置一定的资源使用上限，以防止资源滥用。并支持资源共享，将队列剩余资源共享给其他队列使用。
> 3. **Fair Scheduler**：Fair Scheduler是由Facebook开发的多用户调度器。它的设计目标是为所有应用分配公平的资源（对公平的定义可以通过参数来设置）。公平不仅可以在队列中的应用体现，也可以在多个队列之间工作。例如，假设有两个用户A和B，他们分别拥有一个队列，且分别设置容量最小为集群的一半，最大为全部集群资源。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。

###### 追问

-  调度器 Capacity Scheduler，  Fair Scheduler 这两种调度器如何区分

- AI-Pormpt ： 在解释 Fair Scheduler 所举得例子中，如果在 Capacity Scheduler 有什么区别呢。

	> 在Capacity Scheduler中，如果用户A的一个任务已经占用了超过该队列最大资源使用上限的资源，且其他队列都已经获得了它们的最低资源保证，那么Capacity Scheduler不会强制用户A的任务释放已经占用的资源。
	>
	> Capacity Scheduler以队列为单位划分资源，每个队列可设定一定比例的资源最低保证和使用上限。当一个队列中的任务占用了超过该队列最大资源使用上限的资源时，Capacity Scheduler不会强制该任务释放已经占用的资源。相反，它会继续运行该任务，直到该任务完成或被杀死。
	>
	> 总之，在Capacity Scheduler中，当一个队列中的任务占用了超过该队列最大资源使用上限的资源时，Capacity Scheduler不会强制该任务释放已经占用的资源。相反，它会继续运行该任务，直到该任务完成或被杀死。



工作经验



#### **4. Hadoop集群中分别需要启动哪些进程，它们的作用分别是什么?**

相关问题：

> **非高可用下**
>
> 1. **NameNode**（NN : hdfs的 master ，管理文件系统名称空间（Namespace）和客户端对文件的访问，维护元数据（metadata）。
>
> 	NameNode 是 Hadoop 分布式文件系统（HDFS）的主服务器，负责管理文件系统的名称空间和客户端对文件的访问。它维护着整个文件系统的目录树和所有文件和目录的元数据，包括每个文件的块列表、块位置、副本数等信息。客户端在访问 HDFS 中的文件时，需要先与 NameNode 通信以获取文件的位置信息，然后才能直接与 DataNode 通信以读写文件数据。
>
> 2. **SecondaryNameNode** ： 并非NameNode的热备，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。
>
> 	Hadoop 分布式文件系统（HDFS）中的一个辅助守护进程，它并不是 NameNode 的备份节点，也不提供故障转移功能。它的主要作用是定期合并 NameNode 的文件系统镜像和编辑日志，以防止编辑日志过大，减少 NameNode 重启时的恢复时间。SecondaryNameNode 还可以在 NameNode 宕机时提供最近的文件系统检查点，以便在 NameNode 重启后快速恢复
>
> 3. **DataNode** ：slave 负责处理存储请求。每个存储数据的节点运行一个datanode守护进程。
>
> 	DataNode 是 Hadoop 分布式文件系统（HDFS）中负责存储数据的节点。它负责管理连接到节点的存储设备，并在这些设备上存储、读取和删除数据块。DataNode 还负责与其他 DataNode 之间的数据块复制，以确保数据的可靠性和容错性。客户端可以直接与 DataNode 通信以读写文件数据，但需要先与 NameNode 通信以获取文件的位置信息。
>
> 4. **ResourceManager**：： Yarn的master。YARN的一个组件，负责整个系统的资源管理和调度。
>
> 	ResourceManager 是 YARN（Yet Another Resource Negotiator）的一个组件，负责整个系统的资源管理和调度。它管理着集群中所有的计算资源，并根据应用程序的需求为它们分配资源。ResourceManager 还负责启动和监控 ApplicationMaster，它是 YARN 中负责单个应用程序管理的组件。
>
> 5. **NodeManager**：Yarn 的slave，单节点的资源管理和任务调度。
>
> 	NodeManager 是 YARN（Yet Another Resource Negotiator）的一个组件，负责单个节点上的资源管理和任务调度。它管理着节点上的计算资源，并根据 ResourceManager 的指令为应用程序分配资源。NodeManager 还负责启动和监控容器（Container），它是 YARN 中用于封装应用程序运行环境和资源的组件。 
>
> 6. **JobHistoryServer**：Yarn 组件，Yarn上运行的任务的日志。
>
> 	YARN（Yet Another Resource Negotiator）的一个组件，负责存储和管理 MapReduce 作业的历史信息。它记录了每个作业的详细运行信息，包括作业配置、任务进度、计数器、任务日志等。这些信息可以用于分析作业执行情况，帮助开发人员优化作业性能和调试问题。
>
> **高可用下**
>
> NN, DN, RM,NM
>
> - DFSZKFailoverController ：HDFS组件，HA下的NN的故障转移。监控NN的状态，把NN状态同步给ZK。
>
> 	DFSZKFailoverController 是 Hadoop 分布式文件系统（HDFS）中的一个组件，用于在高可用性（HA）配置下实现 NameNode 的故障转移。它负责监控 NameNode 的状态，并及时将状态信息写入 ZooKeeper。当 Active NameNode 出现故障时，DFSZKFailoverController 会协调 Standby NameNode 接管整个文件系统的管理。
>
> - JournalNode ：HDFS组件，HA下NN的故障转移。负责存储NN的编辑日志（editlog)。
>





#### **5. hadoop 有哪些配置文件**

> Hadoop 主要有以下几个配置文件：
>
> 1. **core-site.xml**：包含 Hadoop 核心配置，如 I/O 设置、文件系统设置等。
> 2. **hdfs-site.xml**：包含 Hadoop 分布式文件系统（HDFS）的配置，如副本数、数据块大小等。
> 3. **mapred-site.xml**：包含 MapReduce 的配置，如作业调度器、任务槽数等。
> 4. **yarn-site.xml**：包含 YARN（Yet Another Resource Negotiator）的配置，如资源管理器地址、调度器设置等。

##### 子问题

- **有些那重点配置项**

	>
	>
	>



### 二、HDFS 的 block相关

**概述题: 简单聊聊你对block 理解：**

> 1. 是什么：在 Hadoop 分布式文件系统（HDFS）中，文件被分割成多个固定大小的数据块（block），并分布存储在集群中的多个 DataNode 上。每个数据块都有多个副本，分布在不同的 DataNode 上，以提供数据的可靠性和容错性。
>
> 	数据块的大小是可以配置的，默认值为 128MB。将文件分割成多个数据块有助于提高并行处理能力，因为多个数据块可以同时在不同的节点上进行处理。
>
> 2. 副本机制：
>
> 	在 HDFS 中，block 默认会被保存三份，这也被称为副本（replica）。
>
> 	这种副本的机制被称为数据冗余（data redundancy），它的目的是为了提高数据的可靠性和可用性。当某个副本不可用时，HDFS 可以使用其他副本来保证数据的可用性。
>
> 	同时，HDFS 还会定期地对副本进行校验，确保它们的一致性。可以通过修改 HDFS 的配置来改变副本的数量。
>
> 	但是需要注意的是，增加副本数量会占用更多的存储空间和网络带宽，因此需要根据实际情况进行权衡。
>
> 3. 块大小：默认 BlockSize = 128; 可以通过配置文件修改，但是不建议。如果有大量的小文件，可以考虑先合并小文件。

**1. HDFS 中的 block 默认保存几份**

> 3份

**2. hadoop block（块）大小：**

> 相关: HDFS默认的BlockSize 多大？
>
> Hadoop1.x都是64M，hadoop2.x开始都是128M。
>
> **HDFS的BlockSzie为什么是128M，增大或者减小有什么影响**
>
> 如果数据块大小过小，那么文件会被分割成更多的数据块，这会增加 NameNode 的元数据管理开销，并降低整体性能。另外，小数据块也会导致更多的磁盘寻道操作，降低磁盘 I/O 性能。
>
> 如果数据块大小过大，那么小文件可能无法充分利用整个数据块，导致存储空间浪费。另外，大数据块也会降低并行处理能力，因为同一时间内可以处理的数据块数量减少。

### 三、HDFS的流程相关

**1 HDFS写流程**

> 1. **客户端请求NN** : 客户端向 NameNode 发送写入请求，请求中包含文件名、副本数等信息。
> 2. **NN检查-分配-回应**：NameNode 检查文件是否已存在，以及客户端是否有写入权限。如果检查通过，NameNode 会为文件分配数据块，并返回给客户端数据块的位置信息。
> 3. **客户端连接DN**：客户端根据数据块的位置信息，选择距离最近的 DataNode，并与其建立连接。
> 4. **切分文件**：客户端将数据分成多个数据包，依次发送给 DataNode。DataNode 在接收到数据包后，会将其暂存到本地磁盘上。
> 5. **DN写入、备份**当一个数据块写满后，DataNode 会将该数据块复制到其他 DataNode 上，以创建副本。复制过程中，DataNode 之间会直接通信，不经过客户端。
> 6. **NN更新元数据，相应** ：当所有数据块都写入完成后，客户端向 NameNode 发送完成信号。NameNode 在接收到完成信号后，会更新元数据，并返回写入成功的消息给客户端。

**2 HDFS读流程**

> 1. **请求**：客户端向 NameNode 发送读取请求，请求中包含文件名等信息。
> 2. **检查，响应**：NameNode 检查文件是否存在，以及客户端是否有读取权限。如果检查通过，NameNode 会返回给客户端数据块的位置信息。
> 3. **客户端连接DN**：客户端根据数据块的位置信息，选择距离最近的 DataNode，并与其建立连接。
> 4. **客户端请求DN读**：客户端向 DataNode 发送读取请求，请求中包含数据块 ID 等信息。
> 5. **DN响应**：DataNode 在接收到读取请求后，会从本地磁盘上读取数据块，并将数据返回给客户端。
> 6. **校验**：客户端在接收到数据后，会对数据进行校验。如果校验通过，客户端会继续读取下一个数据块；如果校验失败，客户端会重新选择其他 DataNode 读取该数据块。

其实还是对读写流程步骤细节熟悉。

**3. HDFS在读取文件的时候，如果其中一个块突然损坏了怎么办**

> 1. **客户端发现**：客户端有校验机制（checksum），校验结果如果不一致会报告NnameNode，客户端将会自动从其他 DataNode 上读取该数据块的副本。
>
> 2. **HDFS处理**：当客户端读取到损坏的数据块时，它会向 NameNode 报告该问题。NameNode 在接收到报告后，会将损坏的数据块标记为无效，并安排创建新的副本以保证数据的可靠性。
>

**相关问题**

**HDFS在上传文件的时候，如果其中一个DataNode突然挂掉了怎么办**

1. **客户端发现** : 在 Hadoop 分布式文件系统（HDFS）中，客户端在上传数据时会使用数据流管道（data streaming pipeline）技术，将数据分成多个数据包依次发送给 DataNode。每个 DataNode 在接收到数据包后，会向客户端发送确认消息（ACK），表示已经成功接收到数据。
2. **HDFS处理**：当DataNode突然挂掉了，客户端会通知NameNode，NameNode将挂掉的 DataNode 标记为不可用，然后安排重新创建丢失的副本。

​			

### 四、小文件相关

**概述：**

> 每个元数据对象约占150byte，所以如果有1千万个小文件，每个文件占用一个block，则NameNode大约需要2G空间
>
> - 量级估算
>
> 	1000(千)     => 1M
>
> 	100000(十万)  => 100M
>
> 	1000000（百万）=> 1G
>
> 	1000000000(十亿) => 10G
>
> 	1000000000000(万亿) => 1T

**HDFS 小文件过多会有什么危害，如何避免**

> 危害
>
> 1. 小文件过多会导致namenode元数据特别大，占用太多内存，严重影响HDFS的性能。
> 2. 并发低，影响吞吐量：对于hive的查询，例如在进行查询时，每个小文件都会当成一个块，启动一个Map任务来完成，而一个Map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的Map数量是受限的
>
> 措施
>
> 解决方案之一是在HDFS存储之前就进行合并，还有一种就是计算完之后根据业务周期来进行合并。
>
> - 例如：Apache 官方工具 Hadoop Archive或者HAR ，是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时，仍然允许对文件进行透明的访问。

### 五、Shuffle过程（核心步骤）

**概述：**

> 注意 1. 结合wordcount解释，解释每部产生的数据结构；2. 必须说明分区怎么参与shuffle和reduce的 



#### MapTask流程

概述

> 

#### ReduceTask流程

概述

> 









