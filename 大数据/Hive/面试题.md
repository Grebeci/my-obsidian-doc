## 基础知识

### Hive基本数据类型

### Hive里timestamp怎么转date

### Hive on MR 和hive on sprak的区别

- 计算引擎不一样，MR比较慢，Spark引擎快。
- Spark 引擎是基于内存的，他能将数据缓存在内存中，从而加跨计算速度。MR是基于磁盘的，因为他map和reduce阶段都要落盘。



### hive中有没有遇到过数据倾斜，怎么处理的

**举个例子：**

它通过在key前面添加随机前缀来打散数据，使数据更均匀地分布在不同的reduce任务中，从而减少数据倾斜的影响。

下面是一个简单的例子，假设我们有一个表`mytable`，其中有两个字段`key`和`value`。我们想要对这个表进行分组求和操作，但是由于某些key值出现的次数过多，导致数据倾斜。为了解决这个问题，我们可以在key前面添加随机前缀来打散数据：

```sql
SELECT key, SUM(value)
FROM (
    SELECT key, value
    FROM mytable
    DISTRIBUTE BY CONCAT(RAND(), key)
) t
GROUP BY key;
```

复制

上面的SQL语句中，我们使用`DISTRIBUTE BY CONCAT(RAND(), key)`来打散数据。这样，在shuffle阶段，相同的key值就会被分配到不同的reduce任务中，从而减少数据倾斜的影响。



- 如果是紧急的值班任务，加大map，reduce的资源，cpu，memory
- 找出倾斜的原因 -- 引起倾斜的key
- 哪种问题的倾斜
	- group by  map聚合、负载均衡。
	- join map join（目的是避免落盘）。
- 代码写的不行 => count(distinct0) , 子查询改用lefjoin 甚至是 left semi join



### 有没有遇到过数据丢失，或者重复的问题 ，怎么解决

###### 重复的问题

这个太常见了，

有一个数据表，它是由20多个子任务sql跑出来join上的，连接键是id，经常出现重复。后端拉取我们数据会校验是否重复，然后会通知我们，这时候我们重跑问题就没有了。

- 很奇怪，据老员工说已经持续了二个月，偶发性大概一周一次。

当再出现重复的时候，我先保存下产生的数据文件，然后重跑，果然没有错误了。

我重新审计了每个子SQL，单独执行，没有一个id是重复的。于是重新看业务逻辑，每个仔细的CR他的代码，终于看到有这个代码片段：

```	
time > current_date
```

刚开始我没有怀疑，因为我们要求这个任务7点之前产出，我看了下执行时间，都是凌晨三点执行完毕。

后来我留意到，在上个月，由于这个任务经常超时，我领导将他的执行时间跳到了前一天的12点之前，（因为会依赖上游的表，上游一般会在凌晨两点执行完毕，我们任务会挂起等着。所以不会提前执行）。

而由于 current_date 这些函数的特性，他保证执行期间这些量不变，相当于编译期就进行了常量替换。。。

直接导致有些表是前一天的数据，肯定会重复了。。

##### 丢失的问题

这个也很常见，一般都是依赖配置，类型转换，的问题。

我们跑完会起一个验证任务，验证量级、各个key的占比，然后和上游的对比，如果不对就重跑，重跑一般三次。



### 数仓建模方面聊聊





### 平时数据量多少



### 平时负责比较多的工作



### 你们数仓架构选型



### 你们数仓的是怎么建模的

### 有没有用过拉链表，讲讲

### 又问我建模完成后怎么检验整个数仓建模的质量



### 说一下离线中做了哪些指标

### 主要经历

### 你对分区和分片是怎么理解的？

### 讲了一下我主要工作内容

### 2.说一说为什么要数仓分层

### 4.说一下hive小文件问题

### 数据量+集群配置



1. Spark的版本和对应的新特性

主要是spark3.0之后的sparksql的AQE和动态分区裁剪

  AQE里面涉及了动态合并shuffle partition ， 动态调整join 策略，动态优化倾斜join

(2) 取所有用户排名Top5？



